{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43827d0d-9c55-4714-94f9-b29d7f0df488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pandas mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854da8ab-3244-439b-bfff-4aec29f67860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba2e3a-6b19-4184-bfb3-74ce9bd03d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./eval_shortcut.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da584d-a95e-4890-a261-5e739644d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['st_sim', 'bert_sim',\n",
    "       'bert_info_ratio', 'tf-idf_info_ratio', 'num_q_ne',\n",
    "       'num_a_ne',  'ne_unique_diff', 'len_q_token', 'len_a_token']\n",
    "x = train.loc[:, feature_names]\n",
    "y = train.loc[:,'rating_shortcut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a99d93-e839-423d-98fc-893584d87ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "def discretize(df, bins=3):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "            df[col] = pd.qcut(df[col], bins, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "\n",
    "high_rating_threshold = y.quantile(0.7)\n",
    "y_high = y >= high_rating_threshold\n",
    "\n",
    "\n",
    "X_discretized = discretize(x.copy())\n",
    "df = X_discretized.copy()\n",
    "df['high_rating'] = y_high\n",
    "\n",
    "\n",
    "df_dummies = pd.get_dummies(df)\n",
    "\n",
    "frequent_itemsets = apriori(df_dummies, min_support=0.05, use_colnames=True)\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "high_rating_rules = rules[rules['consequents'].apply(lambda x: 'high_rating' in str(x))]\n",
    "\n",
    "high_rating_rules = high_rating_rules.sort_values(by='confidence', ascending=False)\n",
    "\n",
    "for _, rule in high_rating_rules.head(3).iterrows():\n",
    "    antecedents = rule['antecedents']\n",
    "    consequents = rule['consequents']\n",
    "    support = rule['support']\n",
    "    confidence = rule['confidence']\n",
    "    lift = rule['lift']\n",
    "    print(f\"Rule: {antecedents} => {consequents}\")\n",
    "    print(f\"Support: {support:.2f}, Confidence: {confidence:.2f}, Lift: {lift:.2f}\\n\")\n",
    "\n",
    "    \n",
    "data = pd.read_csv('./22-8.csv', encoding='utf-8')\n",
    "def filter_dataframe(df, conditions):\n",
    "    condition_strs = []\n",
    "    for cond in conditions:\n",
    "        feature, bin_range = cond.split('_(')\n",
    "        bin_range = bin_range.rstrip(']')\n",
    "        lower, upper = map(float, bin_range.split(', '))\n",
    "        condition_strs.append(f'({lower} <= `{feature}`) & (`{feature}` < {upper})')\n",
    "    query_str = ' & '.join(condition_strs)\n",
    "    return df.query(query_str)\n",
    "\n",
    "\n",
    "filtered_dfs = []\n",
    "for _, rule in high_rating_rules.head(3).iterrows():\n",
    "    conditions = rule['antecedents']\n",
    "    filtered_df = filter_dataframe(data, conditions)\n",
    "    filtered_dfs.append(filtered_df)\n",
    "\n",
    "for i, filtered_df in enumerate(filtered_dfs):\n",
    "    if i > 0:\n",
    "        break\n",
    "    print(filtered_df.shape)\n",
    "    filtered_df.to_csv(f'0525_report_filtered_df_3_.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326738a-b0ee-45b2-858f-c202d266c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./22-8.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34636628-40c9-4352-a402-4212cc2898ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./22-8.csv', encoding='utf-8')\n",
    "\n",
    "def filter_dataframe(df, conditions):\n",
    "    condition_strs = []\n",
    "    for cond in conditions:\n",
    "        feature, bin_range = cond.split('_(')\n",
    "        bin_range = bin_range.rstrip(']')\n",
    "        lower, upper = map(float, bin_range.split(', '))\n",
    "        condition_strs.append(f'({lower} <= `{feature}`) & (`{feature}` < {upper})')\n",
    "    query_str = ' & '.join(condition_strs)\n",
    "\n",
    "    return df.query(query_str)\n",
    "\n",
    "\n",
    "filtered_dfs = []\n",
    "for _, rule in high_rating_rules.head(3).iterrows():\n",
    "    conditions = rule['antecedents']\n",
    "    filtered_df = filter_dataframe(data, conditions)\n",
    "    filtered_dfs.append(filtered_df)\n",
    "\n",
    "for i, filtered_df in enumerate(filtered_dfs):\n",
    "    if i > 0:\n",
    "        break\n",
    "    print(filtered_df.shape)\n",
    "    filtered_df.to_csv(f'5025_report_filtered_df_1_.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8366364-991e-4045-8b7e-b878632ed73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./filtered_df_rule_1.csv', encoding='utf-8')\n",
    "data1.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
